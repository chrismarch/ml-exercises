{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77153405",
   "metadata": {},
   "source": [
    "# Chapter 9 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097f07a",
   "metadata": {},
   "source": [
    "1. _How would you define clustering? Can you name a few clustering algorithms?_<br>\n",
    "<br>\n",
    "Clustering is a technique for grouping instances in a dataset.<br>\n",
    "Some example algorithms are K-Means, DBSCAN, and agglomerative clustering<br>\n",
    "<br>\n",
    "1. _What are some of the main applications of clustering algorithms?_<br>\n",
    "<br>\n",
    "To explore patterns in the dataset, find relationships, specifically:anomaly detection, dimensionality reduction or feature engineering (with affinity vectors), semi-suspervised learning.<br><br>\n",
    "1. _Describe two techniques to select the right number of clusters when using K-Means._<br>\n",
    "<br>\n",
    "You can look for the elbow in the inertia vs. cluster graph, which will give a rough idea. A better technique is to try and maximize the silhouette score. The best technique is to analyze silhouette diagrams and choose the cluster number that gives even clusters compared with the silhouette score.\n",
    "<br><br>\n",
    "1. _What is label propagation? Why would you implement it, and how?_<br>\n",
    "<br>\n",
    "A technique for generating labels when your coverage of the dataset is sparse, and you'd like to perform supervised learning, for example.<br><br>\n",
    "1. _Can you name two clustering algorithms that can scale to large datasets? And two that look for regions of high density?_<br>\n",
    "<br>\n",
    "large datasets: BIRCH, agglomerative clustering <br>\n",
    "high density: DBSCAN, Mean-Shift<br><br>\n",
    "1. _Can you think of a use case where active learning would be useful? How would you implement it?_<br>\n",
    "<br>\n",
    "Identification of objects in images from self-driving car cameras.<br>\n",
    "Force the public to label the images to prove that they are humans on websites.\n",
    "<br><br>\n",
    "1. _What is the difference between anomaly detection and novelty detection?_<br>\n",
    "<br>\n",
    "Novelty detection assumes no outliers in the training set, while anomaly detection does not.\n",
    "<br><br>\n",
    "1. _What is a Gaussian mixture? What tasks can you use it for?_<br>\n",
    "<br>\n",
    "A probabalistic model that assumes instances were generated from several Gaussian distributions<br>\n",
    "Anomaly detection, generating new instances.\n",
    "<br><br>\n",
    "1. _Can you name two techniques to find the right number of clusters when using a Gaussian mixture model?_<br>\n",
    "<br>\n",
    "Find the number of clusters that minimizes the Bayesian information criterion (BIC) or the Akaike information criterion.<br>\n",
    "Alternatively, fit a BayesianGaussianMixture with the n_components set to slightly more clusters than you believe exist, and it will eliminate the unnecessary ones.\n",
    "<br><br>\n",
    "1. _The classic Olivetti faces dataset contains 400 grayscale 64 × 64–pixel images of faces. Each image is flattened to a 1D vector of size 4,096. 40 different people were photographed (10 times each), and the usual task is to train a model that can predict which person is represented in each picture. Load the dataset using the sklearn.datasets.fetch_olivetti_faces() function, then split it into a training set, a validation set, and a test set (note that the dataset is already scaled between 0 and 1). Since the dataset is quite small, you probably want to use stratified sampling to ensure that there are the same number of images per person in each set. Next, cluster the images using K-Means, and ensure that you have a good number of clusters (using one of the techniques discussed in this chapter). Visualize the clusters: do you see similar faces in each cluster?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cde7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "data_bunch = fetch_olivetti_faces()\n",
    "X = data_bunch['data']\n",
    "y = data_bunch['target']\n",
    "images = data_bunch['images']\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=.15)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train_val, X_test = X[train_index], X[test_index]\n",
    "    y_train_val, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "for train_index, test_index in sss.split(X_train_val, y_train_val):\n",
    "    X_train, X_val = X_train_val[train_index], X_train_val[test_index]\n",
    "    y_train, y_val = y_train_val[train_index], y_train_val[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cee33ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 0.13115476\n",
      "31 0.1340997\n",
      "32 0.13530229\n",
      "33 0.13697809\n",
      "34 0.13908912\n",
      "35 0.13951124\n",
      "36 0.14424169\n",
      "37 0.14609942\n",
      "38 0.14126341\n",
      "39 0.14870581\n",
      "40 0.1513849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "kmeans = []\n",
    "for i in range(30, 41):\n",
    "    km = KMeans(n_clusters=i, random_state=0).fit(X_train)\n",
    "    kmeans.append(km)\n",
    "    s = silhouette_score(X_train, km.labels_)\n",
    "    print(str(i) + ' ' + str(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01065ff7",
   "metadata": {},
   "source": [
    "11. _Continuing with the Olivetti faces dataset, train a classifier to predict which person is represented in each picture, and evaluate it on the validation set. Next, use K-Means as a dimensionality reduction tool, and train a classifier on the reduced set. Search for the number of clusters that allows the classifier to get the best performance: what performance can you reach? What if you append the features from the reduced set to the original features (again, searching for the best number of clusters)?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49269676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ac6f392",
   "metadata": {},
   "source": [
    "12. _Train a Gaussian mixture model on the Olivetti faces dataset. To speed up the algorithm, you should probably reduce the dataset’s dimensionality (e.g., use PCA, preserving 99% of the variance). Use the model to generate some new faces (using the sample() method), and visualize them (if you used PCA, you will need to use its inverse_transform() method). Try to modify some images (e.g., rotate, flip, darken) and see if the model can detect the anomalies (i.e., compare the output of the score_samples() method for normal images and for anomalies)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d6610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0156277",
   "metadata": {},
   "source": [
    "13. _Some dimensionality reduction techniques can also be used for anomaly detection. For example, take the Olivetti faces dataset and reduce it with PCA, preserving 99% of the variance. Then compute the reconstruction error for each image. Next, take some of the modified images you built in the previous exercise, and look at their reconstruction error: notice how much larger the reconstruction error is. If you plot a reconstructed image, you will see why: it tries to reconstruct a normal face._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a0d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77153405",
   "metadata": {},
   "source": [
    "# Chapter 5 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097f07a",
   "metadata": {},
   "source": [
    "1. _What is the fundamental idea behind Support Vector Machines?_\n",
    " \n",
    " wide margin separation, for better generalization\n",
    "\n",
    "\n",
    "2. _What is a support vector?_\n",
    "\n",
    " data point that defines the outer margin\n",
    "\n",
    "\n",
    "3. _Why is it important to scale the inputs when using SVMs?_\n",
    "\n",
    " they are sensitive to scale, and need bias removed\n",
    "\n",
    "\n",
    "4. _Can an SVM classifier output a confidence score when it classifies an instance? What about a probability?_ \n",
    "\n",
    " yes. no\n",
    " \n",
    " \n",
    "5. _Should you use the primal or the dual form of the SVM problem to train a model on a training set with millions of instances and hundreds of features?_ \n",
    "\n",
    " (skipped, optional section, question omitted in 3rd edition)\n",
    " \n",
    " \n",
    "6. _Say you’ve trained an SVM classifier with an RBF kernel, but it seems to underfit the training set. Should you increase or decrease γ (gamma)? What about C?_ \n",
    "\n",
    " increase. increase\n",
    "\n",
    "\n",
    "7. _How should you set the QP parameters (H, f, A, and b) to solve the soft margin linear SVM classifier problem using an off-the-shelf QP solver?_ \n",
    "\n",
    " (skipped, optional section, question omitted in 3rd edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3686578",
   "metadata": {},
   "source": [
    "## 8.\n",
    "_Train a LinearSVC on a linearly separable dataset. Then train an SVC and a SGDClassifier on the same dataset. See if you can get them to produce roughly the same model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aef0d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())\n",
    "X = iris[\"data\"][:, 3:]  # petal width\n",
    "y = (iris[\"target\"] == 2).astype(int)  # 1 if Iris setosa, else 0\n",
    "\n",
    "\n",
    "linsvc_class = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=1, loss=\"squared_hinge\", random_state=42)),\n",
    "    ])\n",
    "\n",
    "svc_class = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(random_state=42, kernel='linear', C=1)),\n",
    "    ])\n",
    "\n",
    "sgd_class = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"sgd\", SGDClassifier(random_state=42, loss=\"squared_hinge\", alpha=1/(X.shape[0] * 1), max_iter=1000000))#, early_stopping=True)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42395da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def display_scores(estimator, scores):\n",
    "    print(\"\\n\")\n",
    "    print(type(estimator).__name__)\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "        \n",
    "def print_cv_scores(estimators, X, y):\n",
    "    scores_and_estimators = []\n",
    "    for e in estimators:\n",
    "        scores = cross_val_score(e, X, y, cv=3, verbose=3)\n",
    "        scores_and_estimators.append((scores.mean(), scores, e))\n",
    "        \n",
    "    scores_and_estimators.sort(key = lambda x: x[0], reverse=True)\n",
    "    for mean, scores, e in scores_and_estimators:\n",
    "        display_scores(e, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6313eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [svc_class, linsvc_class, sgd_class]\n",
    "print_cv_scores(estimators, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22437740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismarch/OtherRepos/ml/ml_env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_cvp_linsvc = cross_val_predict(linsvc_class, X, y, cv=5)\n",
    "#print(y_cvp_linsvc)\n",
    "\n",
    "y_cvp_svc = cross_val_predict(svc_class, X, y, cv=5)\n",
    "#print(y_cvp_svc)\n",
    "\n",
    "y_cvp_sgd = cross_val_predict(sgd_class, X, y, cv=5)\n",
    "#print(y_cvp_sgd)\n",
    "\n",
    "print ((y_cvp_linsvc - y_cvp_svc).sum())\n",
    "print ((y_cvp_linsvc - y_cvp_sgd).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3e12c",
   "metadata": {},
   "source": [
    "## 9.\n",
    "_Train an SVM classifier on the MNIST dataset. Since SVM classifiers are binary classifiers, you will need to use one-versus-the-rest to classify all 10 digits. You may want to tune the hyperparameters using small validation sets to speed up the process. What accuracy can you reach?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81135cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128dffcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minst.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(mnist, \"minst.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff2fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "mnist = joblib.load(\"minst.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff958ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "y = y.astype(np.uint8)\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6a3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "linsvc_clf = LinearSVC(C=.09, max_iter=2000, dual=False, random_state=42) # ,  hinge unsuppored with dual=False loss=\"hinge\", penalty='l2',\n",
    "\n",
    "# too slow for MINST (M=70,000)\n",
    "svc_clf = Pipeline([\n",
    "        #(\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(random_state=42, kernel='linear', C=1)),\n",
    "    ])\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_tune_clf = SGDClassifier(random_state=42, alpha=.0001, max_iter=900)#, early_stopping=True, n_iter_no_change=100, alpha=.0002, max_iter=900)#, loss=\"squared_hinge\", alpha=1/(X.shape[0] * 1), max_iter=1000000))#, early_stopping=True)),\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c4b00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb042a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm, y_train_sm = X_train_scaled[:10000], y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1745bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/chrismarch/OtherRepos/ml/ml_env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.899) total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismarch/OtherRepos/ml/ml_env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.891) total time= 3.7min\n",
      "[CV] END ................................ score: (test=0.902) total time= 3.9min\n",
      "\n",
      "\n",
      "SGDClassifier\n",
      "Scores: [0.8987 0.8912 0.9022]\n",
      "Mean: 0.8973666666666666\n",
      "Standard deviation: 0.004588633299312078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismarch/OtherRepos/ml/ml_env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 11.3min finished\n"
     ]
    }
   ],
   "source": [
    "#print_cv_scores([linsvc_clf], X_train_scaled, y_train)\n",
    "print_cv_scores([sgd_tune_clf], X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b96178",
   "metadata": {},
   "source": [
    "### CV Scores\n",
    "\n",
    "LinearSVC C=.1  \n",
    "Scores: [0.90555 0.90555 0.9092 ]\n",
    "Mean: 0.9067666666666666\n",
    "Standard deviation: 0.0017206265008872855\n",
    "\n",
    "SGDClassifier  \n",
    "Scores: [0.8983 0.891  0.9018]\n",
    "Mean: 0.8970333333333333\n",
    "Standard deviation: 0.004499135719471274\n",
    "\n",
    "SGDClassifier tune  \n",
    "Scores: [0.8987 0.8912 0.9022]\n",
    "Mean: 0.8973666666666666\n",
    "Standard deviation: 0.004588633299312078\n",
    "\n",
    "#### 10k subset\n",
    "\n",
    "SGD  \n",
    "Scores: [0.89172166 0.90939094 0.8889889 ]\n",
    "Mean: 0.8967004978842216\n",
    "Standard deviation: 0.009042583092445447\n",
    "\n",
    "LSVC c=.1  \n",
    "Scores: [0.87822436 0.89288929 0.87668767]\n",
    "Mean: 0.8826004376082479\n",
    "Standard deviation: 0.007302314581355561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b11a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "linsvc_param_grid = [\n",
    "    {'C' : [.0925, .09, .088], 'max_iter' : [2000,2200,1850]}#,'loss' : ['hinge', 'squared_hinge']},\n",
    "  ]\n",
    "\n",
    "sgd_param_grid = [\n",
    "    {'alpha' : [0.0001, 0.00005, 0.0015]}#, 'max_iter' : [900,920,850]}#,'loss' : ['hinge', 'squared_hinge']},\n",
    "  ]\n",
    "\n",
    "grid_search = GridSearchCV(sgd_clf, sgd_param_grid, cv=3,\n",
    "                           #return_train_score=True, \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96c5ca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismarch/OtherRepos/ml/ml_env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................................alpha=0.0001; total time= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismarch/OtherRepos/ml/ml_env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................................alpha=0.0001; total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismarch/OtherRepos/ml/ml_env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................................alpha=0.0001; total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismarch/OtherRepos/ml/ml_env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................................alpha=5e-05; total time= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismarch/OtherRepos/ml/ml_env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................................alpha=5e-05; total time= 4.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrismarch/OtherRepos/ml/ml_env/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................................alpha=5e-05; total time=20.9min\n",
      "[CV] END .......................................alpha=0.0015; total time=  54.5s\n",
      "[CV] END .......................................alpha=0.0015; total time=  52.0s\n",
      "[CV] END .......................................alpha=0.0015; total time=  54.9s\n",
      "{'alpha': 0.0015}\n"
     ]
    }
   ],
   "source": [
    "pipe_out = grid_search.fit(X_train_scaled, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "701fca08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744a6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = sgd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01379001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8161582089093642"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_predict, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e03c2c",
   "metadata": {},
   "source": [
    "## test scores\n",
    "LinearSVC(C=0.09, dual=False, max_iter=2000, random_state=42)\n",
    "0.768437796254467\n",
    "\n",
    "SGDClassifier(alpha=0.0002, early_stopping=True, max_iter=900,\n",
    "              n_iter_no_change=100, random_state=42)\n",
    "0.7758249617681228\n",
    "\n",
    "default sgd\n",
    "0.8161582089093642"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1800ffb",
   "metadata": {},
   "source": [
    "## 10.\n",
    "_Train and fine-tune an SVM regressor on the California housing dataset. You can use the original dataset rather than the tweaked version we used in Chapter 2. The original dataset can be fetched using sklearn.datasets.fetch_california_housing(). The targets represent hundreds of thousands of dollars. Since there are over 20,000 instances, SVMs can be slow, so for hyperparameter tuning you should use far fewer instances (e.g., 2,000), to test many more hyperparameter combinations. What is your best model’s RMSE?_ (3rd edition elaboration) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b5ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "dataset = sklearn.datasets.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69837157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcc585b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nAn household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surpinsingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36c104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

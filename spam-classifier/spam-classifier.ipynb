{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74c7fa6",
   "metadata": {},
   "source": [
    "This is my solution to an exercise to make a spam classifier using Apache SpamAssassin’s public datasets, which I am writing to learn about machine learning. The exercise is from \n",
    "_Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition_, by\n",
    "Aurélien Géron.\n",
    "\n",
    "Copyright (C) 2022 Chris March <https://github.com/chrismarch>\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806268b",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Load and Preprocess](#Load-and-Preprocess)\n",
    "- [Training](#Training)\n",
    "- [Scoring](#Scoring)\n",
    "- [Tuning](#Tuning)\n",
    "- [Submission](#Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff9411",
   "metadata": {},
   "source": [
    "## Load and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea9027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "import email\n",
    "from email import policy\n",
    "from io import StringIO\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8738c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    ''' MLStripper by \"Olivier Le Floch\" https://stackoverflow.com/a/925630 '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self): \n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3ece22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_get_body(b):\n",
    "    ''' \n",
    "    email_get_body by Todor Minikov https://stackoverflow.com/a/32840516\n",
    "    (this seems to be more robust, or at least easier to use without errors than email.Parser.get_body)\n",
    "    '''\n",
    "    body = \"\"\n",
    "    if b.is_multipart():\n",
    "        for part in b.walk():\n",
    "            ctype = part.get_content_type()\n",
    "            cdispo = str(part.get('Content-Disposition'))\n",
    "\n",
    "            # skip any text/plain (txt) attachments\n",
    "            if ctype == 'text/plain' and 'attachment' not in cdispo:\n",
    "                body = part.get_payload(decode=True)  # decode\n",
    "                break\n",
    "    # not multipart - i.e. plain text, no attachments, keeping fingers crossed\n",
    "    else:\n",
    "        body = b.get_payload(decode=True)\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35285314",
   "metadata": {},
   "source": [
    "hyperparameters to your preparation pipeline to control whether or not to \n",
    "- strip off email headers, \n",
    "- convert each email to lowercase, \n",
    "- remove punctuation, \n",
    "- replace all URLs with “URL,” \n",
    "- replace all numbers with “NUMBER,” \n",
    "- or even perform stemming (i.e., trim off word endings; there are Python libraries available to do this).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8910768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_key = 'is_spam'\n",
    "\n",
    "def load_email_files_to_dataframe():\n",
    "    vocabulary = {}\n",
    "    file_paths_to_mail_dicts = {}\n",
    "    file_index = 0\n",
    "    for parent_dir, subdirs, files in os.walk('.'):\n",
    "        #print(parent_dir)\n",
    "        #print(subdirs)\n",
    "        #print('---')\n",
    "        word_regex = re.compile(r\"^[(]?((mp3|MP3)[sS]?|[a-zA-Z]+|[a-zA-Z]+[-\\/]?[a-zA-Z]+|[a-zA-Z]+[-\\/]?[a-zA-Z]+[']?[a-zA-Z]+)([)]?[!?]+|[!?]+[)]?|[.,;:)]?)$\")\n",
    "        html_regex = re.compile(r\"(<html>|<HTML>)(.*)(<\\/html>|<\\/HTML>)\", re.DOTALL)\n",
    "        hamdir = '_ham' in parent_dir\n",
    "        spamdir = 'spam' in parent_dir\n",
    "        if hamdir or spamdir:\n",
    "            for file in files:\n",
    "                file_index += 1\n",
    "                rel_file_path = os.path.join(parent_dir, file) \n",
    "                #print(rel_file_path)\n",
    "                with open(rel_file_path, 'r', encoding='iso-8859-1') as f:\n",
    "                #with open(rel_file_path, 'rb') as f:\n",
    "                    f_str = f.read()   \n",
    "                    msg = email.message_from_string(f_str, policy=policy.default)\n",
    "                    #msg = email.parser.BytesParser(policy=policy.default).parse(f)\n",
    "                    if file_index % 1000 == 0:\n",
    "                        print(str(file_index))\n",
    "                    subject = msg['subject']\n",
    "                    #print(subject)\n",
    "                    #print(msg['header'])\n",
    "                    #body = msg.get_body(preferencelist=('html', 'plain'))\n",
    "                    #if not body:\n",
    "                    #    continue\n",
    "                    #body = body.get_content()\n",
    "                    body = str(email_get_body(msg))\n",
    "                    #print(body)\n",
    "                    html_match = html_regex.search(body)\n",
    "                    #print(html_match)\n",
    "                    if html_match:\n",
    "                        body = html_match.group(2)\n",
    "                        #print('------------')\n",
    "                        #print(body)\n",
    "                        #print('------------')\n",
    "                    body_strip = strip_tags(body)\n",
    "                    body_strip = re.sub(r\"[()\\\"\\'-]\", '', body_strip)\n",
    "                    #print(body_strip)\n",
    "                    mail_tokens = body_strip.split()\n",
    "                    if subject:\n",
    "                        mail_tokens += subject.split()\n",
    "                    mail_dict = {}\n",
    "                    mail_rejected_tokens = []\n",
    "                    for token in mail_tokens:\n",
    "                        match = word_regex.match(token)\n",
    "                        if match:\n",
    "                            match_group = match.group(1)\n",
    "                            if match_group in mail_dict:\n",
    "                                mail_dict[match_group] = mail_dict[match_group] + 1\n",
    "                            else:\n",
    "                                mail_dict[match_group] = 1\n",
    "                        else:\n",
    "                            mail_rejected_tokens.append(token)\n",
    "                    file_paths_to_mail_dicts[rel_file_path] = mail_dict\n",
    "                    #print(mail_tokens)                            \n",
    "                    #print(mail_dict)\n",
    "                    #print(mail_rejected_tokens)\n",
    "\n",
    "                    #break\n",
    "                \n",
    "    # add all the words to a vocabulary\n",
    "    vocab_i = 0\n",
    "    for file_path in file_paths_to_mail_dicts:\n",
    "        mail_dict = file_paths_to_mail_dicts[file_path]        \n",
    "        for word in mail_dict:\n",
    "            vocabulary[word] = vocab_i\n",
    "            vocab_i += 1\n",
    "            \n",
    "    columns = [spam_key] + list(vocabulary.keys())\n",
    "    n_columns = len(columns)\n",
    "    mail_dicts = []\n",
    "    # for each mail, encode\n",
    "    for file_path in file_paths_to_mail_dicts:\n",
    "        mail_dict = file_paths_to_mail_dicts[file_path]\n",
    "        mail_dict[spam_key] = 1 if 'spam' in file_path else 0\n",
    "        mail_dicts.append(mail_dict)\n",
    "        \n",
    "    # TODO convert to zero fill sparse from nan sparse and serialize zero fill sparse\n",
    "     \n",
    "    nan_df = pd.DataFrame(data=mail_dicts, columns=columns, dtype=pd.SparseDtype(np.dtype('float64'))) # has to be nan to start, fill_value=0))\n",
    "    return pd.DataFrame(data=df, dtype=pd.SparseDtype(np.dtype('float64'), fill_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff47828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: this can take a couple/few minutes    \n",
    "df = load_email_files_to_dataframe()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527a69ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021909544091197348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['spamham.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.sparse.density)\n",
    "joblib.dump(df, \"spamham.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac993293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>you</th>\n",
       "      <th>can</th>\n",
       "      <th>copy</th>\n",
       "      <th>DVDs</th>\n",
       "      <th>and</th>\n",
       "      <th>DVD</th>\n",
       "      <th>VIDEOs</th>\n",
       "      <th>WITH</th>\n",
       "      <th>YOUR</th>\n",
       "      <th>...</th>\n",
       "      <th>Cognitive</th>\n",
       "      <th>Neuroscience</th>\n",
       "      <th>Ribbon</th>\n",
       "      <th>Bennewitz</th>\n",
       "      <th>gpl</th>\n",
       "      <th>wp</th>\n",
       "      <th>interpreters</th>\n",
       "      <th>bDamien</th>\n",
       "      <th>emotitags</th>\n",
       "      <th>Rockall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10746</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10747</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10748</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10749</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10750</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10751 rows × 54021 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_spam  you  can  copy  DVDs  and   DVD  VIDEOs  WITH  YOUR  ...  \\\n",
       "0          1.0  8.0  4.0   3.0   1.0  6.0  12.0     1.0   1.0   1.0  ...   \n",
       "1          1.0  0.0  0.0   1.0   0.0  0.0   0.0     0.0   0.0   0.0  ...   \n",
       "2          1.0  3.0  1.0   0.0   0.0  8.0   0.0     0.0   0.0   0.0  ...   \n",
       "3          1.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0   0.0   0.0  ...   \n",
       "4          1.0  2.0  0.0   0.0   0.0  3.0   0.0     0.0   0.0   1.0  ...   \n",
       "...        ...  ...  ...   ...   ...  ...   ...     ...   ...   ...  ...   \n",
       "10746      0.0  0.0  0.0   0.0   0.0  2.0   0.0     0.0   0.0   0.0  ...   \n",
       "10747      0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0   0.0   0.0  ...   \n",
       "10748      0.0  0.0  0.0   0.0   0.0  0.0   0.0     0.0   0.0   0.0  ...   \n",
       "10749      0.0  3.0  1.0   0.0   0.0  5.0   0.0     0.0   0.0   0.0  ...   \n",
       "10750      0.0  4.0  0.0   0.0   0.0  3.0   0.0     0.0   0.0   0.0  ...   \n",
       "\n",
       "       Cognitive  Neuroscience  Ribbon  Bennewitz  gpl   wp  interpreters  \\\n",
       "0            0.0           0.0     0.0        0.0  0.0  0.0           0.0   \n",
       "1            0.0           0.0     0.0        0.0  0.0  0.0           0.0   \n",
       "2            0.0           0.0     0.0        0.0  0.0  0.0           0.0   \n",
       "3            0.0           0.0     0.0        0.0  0.0  0.0           0.0   \n",
       "4            0.0           0.0     0.0        0.0  0.0  0.0           0.0   \n",
       "...          ...           ...     ...        ...  ...  ...           ...   \n",
       "10746        0.0           0.0     0.0        0.0  0.0  0.0           0.0   \n",
       "10747        0.0           0.0     0.0        0.0  0.0  0.0           0.0   \n",
       "10748        0.0           0.0     0.0        0.0  0.0  0.0           0.0   \n",
       "10749        0.0           0.0     0.0        0.0  0.0  0.0           0.0   \n",
       "10750        0.0           0.0     0.0        0.0  0.0  0.0           0.0   \n",
       "\n",
       "       bDamien  emotitags  Rockall  \n",
       "0          0.0        0.0      0.0  \n",
       "1          0.0        0.0      0.0  \n",
       "2          0.0        0.0      0.0  \n",
       "3          0.0        0.0      0.0  \n",
       "4          0.0        0.0      0.0  \n",
       "...        ...        ...      ...  \n",
       "10746      0.0        0.0      0.0  \n",
       "10747      1.0        1.0      1.0  \n",
       "10748      0.0        0.0      0.0  \n",
       "10749      0.0        0.0      0.0  \n",
       "10750      0.0        0.0      0.0  \n",
       "\n",
       "[10751 rows x 54021 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_data = joblib.load(\"spamham.pkl\")\n",
    "all_data = pd.DataFrame(data=nan_data, dtype=pd.SparseDtype(np.dtype('float64'), fill_value=0))\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f116d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "974009b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021909544091197348\n"
     ]
    }
   ],
   "source": [
    "print(all_data.sparse.density)\n",
    "target_label_col = spam_key\n",
    "\n",
    "for train_indexes, test_indexes in split.split(all_data, all_data[target_label_col]):\n",
    "    strat_train_set = all_data.loc[train_indexes]\n",
    "    strat_test_set = all_data.loc[test_indexes]\n",
    "\n",
    "#print(list(strat_train_set))\n",
    "X_train = strat_train_set.drop(target_label_col, axis=1)\n",
    "y_train = strat_train_set[target_label_col].copy()\n",
    "\n",
    "# test data split from train.csv, since test.csv has no labels\n",
    "X_test = strat_test_set.drop(target_label_col, axis=1)\n",
    "y_test = strat_test_set[target_label_col].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8885a",
   "metadata": {},
   "source": [
    "## Estimator Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cd109d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linsvc_clf = LinearSVC(C=.1)\n",
    "mnb_clf = MultinomialNB()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9014667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "MultinomialNB\n",
      "Mean: 0.9759302325581395\n",
      "Standard deviation: 0.0023139242723409837\n"
     ]
    }
   ],
   "source": [
    "def display_scores(estimator, scores):\n",
    "    print(\"\\n\")\n",
    "    print(type(estimator).__name__)\n",
    "    #print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "        \n",
    "def display_estimator_cv_scores(estimator, X, y): \n",
    "    scores = cross_val_score(estimator, X, y, cv=5)\n",
    "    display_scores(estimator, scores)\n",
    "\n",
    "def print_cv_scores(estimators, X, y):\n",
    "    scores_and_estimators = []\n",
    "    for e in estimators:\n",
    "        scores = cross_val_score(e, X, y, cv=5)\n",
    "        scores_and_estimators.append((scores.mean(), scores, e))\n",
    "        \n",
    "    scores_and_estimators.sort(key = lambda x: x[0], reverse=True)\n",
    "    for mean, scores, e in scores_and_estimators:\n",
    "        display_scores(e, scores)\n",
    " \n",
    "\n",
    "estimators = [mnb_clf]#, linsvc_clf]\n",
    "print_cv_scores(estimators, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ceecb1",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "6ea2a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "class AttributesDropper(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, n_top_to_keep=30): # no *args or **kargs\n",
    "        self.n_top_to_keep = n_top_to_keep\n",
    "        self.cols_to_drop = attr_correlation[0:self.n_top_to_keep]\n",
    "                \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    \n",
    "    def transform(self, X):\n",
    "        self.cols_to_drop = attr_correlation[0:self.n_top_to_keep]\n",
    "        return np.delete(X, self.cols_to_drop, 1)\n",
    "'''\n",
    "\n",
    "class AttributesDropper(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, min_importance=0.01): # no *args or **kargs\n",
    "        self.min_importance = min_importance\n",
    "        self.cols_to_drop = []\n",
    "        for i, t in enumerate(attr_importance_forest):\n",
    "            #print(i, t)\n",
    "            if t[0] < self.min_importance:\n",
    "                self.cols_to_drop.append(i)\n",
    "        #print(self.cols_to_drop)\n",
    "                \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    \n",
    "    def transform(self, X):\n",
    "        self.cols_to_drop = []\n",
    "        for i, t in enumerate(attr_importance_forest):\n",
    "            if i >= np.size(X, 1):\n",
    "                continue\n",
    "            #print(i, t)\n",
    "            if t[0] < self.min_importance:\n",
    "                self.cols_to_drop.append(i)\n",
    "                \n",
    "        #print(self.cols_to_drop)\n",
    "        #print(X)\n",
    "        return np.delete(X, self.cols_to_drop, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e372ec",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6873977c",
   "metadata": {},
   "source": [
    "Finally, try out several classifiers and see if you can build a great spam classifier, with both high recall and high precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "4876be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_param_grid = [\n",
    "    {'n_estimators': [40, 35, 45], 'max_features': [None, \"sqrt\", \"log2\"]},\n",
    "    {'bootstrap': [False], 'n_estimators': [40, 35, 45], 'max_features': [None, \"sqrt\", \"log2\"]},\n",
    "  ]\n",
    "\n",
    "knn_param_grid = [\n",
    "    {'weights': [\"uniform\", \"distance\"], 'n_neighbors': [5, 8, 9, 10, 11, 15, 20, 100]},\n",
    "  ]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(knn_class,knn_param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True, verbose=1)\n",
    "\n",
    "#col_trans.named_transformers_[\"cat\"].handle_unknown = 'ignore' # for dropping attributes\n",
    "\n",
    "main_pipeline = Pipeline([\n",
    "    ('col', col_trans),\n",
    "    ('dropper', AttributesDropper()),\n",
    "#    ('forest', )\n",
    "#     ('knn', knn_class)    \n",
    "#         ('sgd', SGDClassifier(random_state=42))    \n",
    " #   ('dropper', AttributesDropper()),\n",
    "    ('grid', grid_search)\n",
    "])\n",
    "\n",
    "param_drpr = [\n",
    "#    {'dropper__min_importance': [0,.0002,.0004,.00005,.0003]}\n",
    "    {'dropper__min_importance': [0, .061, .07, .08]}\n",
    "\n",
    "     #{'col__verbose': [1,2]}\n",
    "  ]\n",
    "\n",
    "full_pipeline = GridSearchCV(main_pipeline, param_drpr, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           verbose=2)#, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "8d2c1c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.9s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.9s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   1.0s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.9s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   1.0s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   1.0s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   1.2s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   1.1s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   1.0s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   1.0s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "{'dropper__min_importance': 0}\n",
      "{'n_neighbors': 9, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "pipe_out = full_pipeline.fit(X_train, y_train)\n",
    "#pipe_out = main_pipeline.fit(X_train, y_train)\n",
    "#print(grid_search.best_params_)\n",
    "print(full_pipeline.best_params_)\n",
    "print(full_pipeline.best_estimator_.steps[2][1].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49646249",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "5a691f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7795566502463054"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test_tr = col_trans.fit_transform(X_test)\n",
    "#print(list(X_train))\n",
    "#print(list(X_test))\n",
    "\n",
    "# forest\n",
    "# 0.785314498933902\n",
    "# 0.7706711343254163 drop age\n",
    "\n",
    "# knn\n",
    "# 0.7795566502463054\n",
    "\n",
    "# sgd\n",
    "# 0.777129750982962\n",
    "\n",
    "y_test_predict = pipe_out.predict(X_test)\n",
    "score = f1_score(y_test, y_test_predict, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caffa6fc",
   "metadata": {},
   "source": [
    "## RandomForestClassifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "f963017c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.24642056362521655, 'Ticket'),\n",
       " (0.1997771812616029, 'SibSp'),\n",
       " (0.1625302744959772, 'Age'),\n",
       " (0.1310349683247463, 'Name_Mrs'),\n",
       " (0.12822693304238728, 'Fare'),\n",
       " (0.06365665124579165, 'Pclass'),\n",
       " (0.037023662731619195, 'Parch'),\n",
       " (0.020000375176989427, 'Name_Don'),\n",
       " (0.010536099549008712, 'Name_Ms'),\n",
       " (0.0004413942038337618, 'Name_Capt'),\n",
       " (0.000299882278765768, 'Name_Mr'),\n",
       " (5.20140640613997e-05, 'Name_Miss'),\n",
       " (0.0, 'Name_Lady')]"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_importances = full_pipeline.best_estimator_.steps[2][1].best_estimator_.feature_importances_\n",
    "#feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "#feature_importances\n",
    "\n",
    "#print(feature_importances)\n",
    "\n",
    "#cat_encoder = col_pipeline.named_transformers_[\"cat\"]\n",
    "onehot_attribs = col_trans.transformers_[1][1].named_steps['one'].get_feature_names_out()\n",
    "#print(onehot_attribs)\n",
    "#print(num_attribs)\n",
    "attributes = num_attribs + list(onehot_attribs)\n",
    "#list(zip(feature_importances, attributes))\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c8dfcf",
   "metadata": {},
   "source": [
    "## Performance\n",
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "963f6659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.8s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.8s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.8s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.6s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.8s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.8s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.8s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.8s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=0.061; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.07; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.8s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.8s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .......................dropper__min_importance=0.08; total time=   0.8s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8486528657371482"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_scores = cross_val_predict(pipe_out, X_train, y_train, cv=3,\n",
    "                             method=\"predict_proba\")\n",
    "                             #method=\"decision_function\") #SGD\n",
    "    \n",
    "y_scores = y_scores[:, 1]   # score = proba of positive class\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_scores)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonal\n",
    "    [...] # Add axis labels and grid\n",
    "\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()\n",
    "# forest\n",
    "# 0.856909225929727\n",
    "# 0.8557619297938204 drop age\n",
    "\n",
    "# knn\n",
    "# 0.8406051048420068\n",
    "\n",
    "# sgd\n",
    "# n/a\n",
    "\n",
    "roc_auc_score(y_train, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f79d59",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "f2387cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_class_test = LinearRegression()\n",
    "svc_class_test = SVC(random_state=42)\n",
    "forest_class_test = RandomForestClassifier(random_state=42)\n",
    "knn_class_test = KNeighborsClassifier()\n",
    "sgd_class_test = SGDClassifier(random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "cecd5b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_test = GridSearchCV(knn_class_test, knn_param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True, verbose=1)\n",
    "\n",
    "#col_trans.named_transformers_[\"cat\"].handle_unknown = 'ignore' # for dropping attributes\n",
    "\n",
    "main_pipeline_test = Pipeline([\n",
    "    ('col', col_trans),\n",
    "    ('dropper', AttributesDropper()),\n",
    "    ('grid', grid_search_test)\n",
    "])\n",
    "\n",
    "full_pipeline_test = GridSearchCV(main_pipeline_test, param_drpr, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           verbose=2)#, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "34ab0876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ..........................dropper__min_importance=0; total time=   1.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0002; total time=   1.7s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0002; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0002; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0002; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0002; total time=   1.4s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0004; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0004; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0004; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0004; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0004; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=5e-05; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=5e-05; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=5e-05; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=5e-05; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ......................dropper__min_importance=5e-05; total time=   1.6s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0003; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0003; total time=   1.6s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0003; total time=   1.6s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0003; total time=   1.6s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................dropper__min_importance=0.0003; total time=   1.5s\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "all_test_data = load_csv_as_pd(\"test.csv\")\n",
    "all_test_data_pp = preprocess_data(all_test_data)\n",
    "\n",
    "X_train_all = all_train_data_pp.drop(target_label_col, axis=1)\n",
    "y_train_all = all_train_data_pp[target_label_col].copy()\n",
    "\n",
    "pipe_out_test = full_pipeline_test.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "6cc8466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropper__min_importance': 0.0004}\n",
      "{'n_neighbors': 10, 'weights': 'uniform'}\n",
      "(418,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(full_pipeline_test.best_params_)\n",
    "#print(full_pipeline_test.best_estimator_)\n",
    "print(full_pipeline_test.best_estimator_.steps[2][1].best_params_)\n",
    "\n",
    "#print(grid_search_test.named_steps['grid'].best_params_)\n",
    "y_submission = pipe_out_test.predict(all_test_data_pp)\n",
    "print(y_submission.shape)\n",
    "\n",
    "df = pd.DataFrame(y_submission, columns=['Survived'])\n",
    "df.insert(0, \"PassengerId\", all_test_data[\"PassengerId\"], allow_duplicates=True)\n",
    "df.to_csv(\"submission.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0775ff9a",
   "metadata": {},
   "source": [
    "1. 0.75119: forest trained on subset of train.csv\n",
    "2. 0.75598: forest trained on all data\n",
    "3. 0.77751: knn .0001 drop?\n",
    "4. 0.72966: sgd\n",
    "5. 0.77751: knn .0003 drop\n",
    "6. 0.77033: knn .00001 drop\n",
    "7. 0.77751: knn .0004 drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f11aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74c7fa6",
   "metadata": {},
   "source": [
    "This is my solution to an exercise to make a spam classifier using Apache SpamAssassin’s public datasets, which I am writing to learn about machine learning. The exercise is from \n",
    "_Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition_, by\n",
    "Aurélien Géron.\n",
    "\n",
    "Copyright (C) 2022 Chris March <https://github.com/chrismarch>\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806268b",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Load and Preprocess](#Load-and-Preprocess)\n",
    "- [Validate](#Validate)\n",
    "- [Train](#Train)\n",
    "- [Test](#Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff9411",
   "metadata": {},
   "source": [
    "## Load and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea9027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "import email\n",
    "from email import policy\n",
    "from io import StringIO\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e417d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntFlag\n",
    "\n",
    "class PreprocessFlags(IntFlag):\n",
    "    TO_LOWER = 1\n",
    "    STRIP_PUNCTUATION = 2\n",
    "    REPLACE_URLS = 4\n",
    "    REPLACE_NUMBERS = 8\n",
    "    \n",
    "    ALL_IMPLEMENTED_FLAGS = TO_LOWER | STRIP_PUNCTUATION | REPLACE_URLS | REPLACE_NUMBERS\n",
    "    \n",
    "    STRIP_HEADERS = 16     # TODO\n",
    "    STEM = 32              # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13247536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "CATEGORY_LABEL = \"is_spam\"\n",
    "\n",
    "def preprocess_token(token : str, flags : PreprocessFlags) -> str:\n",
    "    \n",
    "    if (token == CATEGORY_LABEL):\n",
    "        return token\n",
    "\n",
    "    if (PreprocessFlags.TO_LOWER in flags):\n",
    "        token = token.lower()\n",
    "\n",
    "    if (PreprocessFlags.REPLACE_URLS in flags):\n",
    "        if re.match(r'http\\S+', token):\n",
    "            token = 'URLREPLACED'\n",
    "\n",
    "    if (PreprocessFlags.STRIP_PUNCTUATION in flags):\n",
    "        token = token.translate(str.maketrans('', '', string.punctuation))    \n",
    "\n",
    "    if (PreprocessFlags.REPLACE_NUMBERS in flags):\n",
    "        token = re.sub(r'[0-9]+', '_N_', token)\n",
    "\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8738c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    ''' MLStripper by \"Olivier Le Floch\" https://stackoverflow.com/a/925630 '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self): \n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3ece22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_get_body(b):\n",
    "    ''' \n",
    "    email_get_body by Todor Minikov https://stackoverflow.com/a/32840516\n",
    "    (this seems to be more robust, or at least easier to use without errors than email.Parser.get_body)\n",
    "    '''\n",
    "    body = \"\"\n",
    "    if b.is_multipart():\n",
    "        for part in b.walk():\n",
    "            ctype = part.get_content_type()\n",
    "            cdispo = str(part.get('Content-Disposition'))\n",
    "\n",
    "            # skip any text/plain (txt) attachments\n",
    "            if ctype == 'text/plain' and 'attachment' not in cdispo:\n",
    "                body = part.get_payload(decode=True)  # decode\n",
    "                break\n",
    "    # not multipart - i.e. plain text, no attachments, keeping fingers crossed\n",
    "    else:\n",
    "        body = b.get_payload(decode=True)\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8910768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_key = 'is_spam'\n",
    "\n",
    "def load_email_files_to_dataframe(flags : PreprocessFlags):\n",
    "    vocabulary = {}\n",
    "    mail_dicts = []\n",
    "    file_index = 0\n",
    "\n",
    "    for parent_dir, subdirs, files in os.walk('.'):\n",
    "        #print(parent_dir)\n",
    "        #print(subdirs)\n",
    "        #print('---')\n",
    "        html_regex = re.compile(r\"(<html>|<HTML>)(.*)(<\\/html>|<\\/HTML>)\", re.DOTALL)\n",
    "        hamdir = '_ham' in parent_dir\n",
    "        spamdir = 'spam' in parent_dir\n",
    "        if hamdir or spamdir:\n",
    "            for file in files:\n",
    "                file_index += 1\n",
    "                rel_file_path = os.path.join(parent_dir, file) \n",
    "                #print(rel_file_path)\n",
    "                with open(rel_file_path, 'r', encoding='iso-8859-1') as f:\n",
    "                #with open(rel_file_path, 'rb') as f:\n",
    "                    f_str = f.read()   \n",
    "                    msg = email.message_from_string(f_str, policy=policy.default)\n",
    "                    #msg = email.parser.BytesParser(policy=policy.default).parse(f)\n",
    "                    if file_index % 1000 == 0:\n",
    "                        print(str(file_index))\n",
    "                    subject = msg['subject']\n",
    "                    #print(subject)\n",
    "                    #print(msg['header'])\n",
    "                    #body = msg.get_body(preferencelist=('html', 'plain'))\n",
    "                    #if not body:\n",
    "                    #    continue\n",
    "                    #body = body.get_content()\n",
    "                    body = str(email_get_body(msg))\n",
    "                    #print(body)\n",
    "                    html_match = html_regex.search(body)\n",
    "                    #print(html_match)\n",
    "                    if html_match:\n",
    "                        body = html_match.group(2)\n",
    "                        #print('------------')\n",
    "                        #print(body)\n",
    "                        #print('------------')\n",
    "                    body_strip = strip_tags(body)\n",
    "                    body_strip = re.sub(r\"\\\\n\", ' ', body_strip)\n",
    "                    body_strip = re.sub(r\"\\\\t\", ' ', body_strip)\n",
    "                    #print(body_strip)\n",
    "                    mail_tokens = body_strip.split()\n",
    "                    if subject:\n",
    "                        mail_tokens += subject.split()\n",
    "                    mail_dict = {}\n",
    "                    mail_rejected_tokens = []\n",
    "                    for token in mail_tokens:\n",
    "                        token = preprocess_token(token, flags)\n",
    "                        if token in mail_dict:\n",
    "                            mail_dict[token] = mail_dict[token] + 1\n",
    "                        else:\n",
    "                            mail_dict[token] = 1\n",
    "                            vocabulary[token] = 0\n",
    "                    mail_dict[spam_key] = 1 if 'spam' in rel_file_path else 0\n",
    "                    mail_dicts.append(mail_dict)\n",
    "                #if file_index > 100:\n",
    "                #break\n",
    "    print('finished loading emails')\n",
    "    \n",
    "    columns = [CATEGORY_LABEL] + list(vocabulary.keys())\n",
    "    del vocabulary\n",
    "    \n",
    "    # TODO find a one step way to zero (instead of nan) fill missing values in sparse DataFrames\n",
    "    nan_df = pd.DataFrame(data=mail_dicts, columns=columns, dtype = pd.SparseDtype(pd.UInt32Dtype()))\n",
    "    del mail_dicts\n",
    "    \n",
    "    return pd.DataFrame(data=nan_df, columns=columns, dtype = pd.SparseDtype(np.dtype('int32'), fill_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff47828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: this can take a couple hours\n",
    "\n",
    "# save out preprocessed binary dataframes, so that the time needed for preprocessing hyperparameters is done once\n",
    "n_flag_combos = PreprocessFlags.ALL_IMPLEMENTED_FLAGS + 1\n",
    "flags_range = range(n_flag_combos)\n",
    "for flags in flags_range:\n",
    "    if flags == 0:\n",
    "        continue\n",
    "    all_data = load_email_files_to_dataframe(PreprocessFlags(flags))\n",
    "    print('---------------- Preprocess: saving ' + str(flags) + 'of [0, ' + str(n_flag_combos) + ']')\n",
    "    print(all_data.sparse.density)\n",
    "    print(all_data.info())\n",
    "    joblib.dump(all_data, \"spamham_flags\" + str(flags) + \".pkl\")\n",
    "    del all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8885a",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9014667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def display_scores(estimator, scores):\n",
    "    print(\"\\n\")\n",
    "    print(type(estimator).__name__)\n",
    "    #print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def print_cv_scores(estimators, X, y):\n",
    "    scores_and_estimators = []\n",
    "    for e in estimators:\n",
    "        scores = cross_val_score(e, X, y, cv=5, verbose=2)\n",
    "        scores_and_estimators.append((scores.mean(), scores, e))\n",
    "\n",
    "    scores_and_estimators.sort(key = lambda x: x[0], reverse=True)\n",
    "    for mean, scores, e in scores_and_estimators:\n",
    "        display_scores(e, scores)\n",
    "\n",
    "def load_train_test_data(flags : PreprocessFlags) -> (str, str, str, str):\n",
    "    ''' Returns X_train, y_train, X_test, y_test '''\n",
    "    \n",
    "    fname = \"spamham_flags\" + str(flags) +\".pkl\"\n",
    "    print(\"loading \" + fname)\n",
    "\n",
    "    all_data = joblib.load(fname)\n",
    "    print(all_data.info())\n",
    "    print(all_data.sparse.density)\n",
    "\n",
    "    #all_data = pd.DataFrame(data=nan_data, dtype=pd.SparseDtype(np.dtype('float64'), fill_value=0))\n",
    "    #nan_data = None\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "    y_all = all_data[CATEGORY_LABEL]\n",
    "    for train_indexes, test_indexes in split.split(all_data, y_all):\n",
    "        strat_train_set = all_data.loc[train_indexes]\n",
    "        strat_test_set = all_data.loc[test_indexes]\n",
    "\n",
    "    del all_data\n",
    "    #print(list(strat_train_set))\n",
    "    X_train = strat_train_set.drop(CATEGORY_LABEL, axis=1)\n",
    "    y_train = strat_train_set[CATEGORY_LABEL].copy()\n",
    "    del strat_train_set\n",
    "\n",
    "    # test data split from train.csv, since test.csv has no labels\n",
    "    X_test = strat_test_set.drop(CATEGORY_LABEL, axis=1)\n",
    "    y_test = strat_test_set[CATEGORY_LABEL].copy()\n",
    "    del strat_test_set\n",
    "    \n",
    "    print(fname)\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "        \n",
    "def validate(preprocessor_flags_range):\n",
    "    for flags in preprocessor_flags_range:\n",
    "        X_train, y_train, X_test, y_test = load_train_test_data(flags)\n",
    "        linsvc_clf = LinearSVC(C=.01)\n",
    "        mnb_clf = MultinomialNB(alpha=1e-4, fit_prior=False)                       \n",
    "\n",
    "        estimators = [mnb_clf]#, linsvc_clf]\n",
    "        #estimators = [linsvc_clf]\n",
    "        print_cv_scores(estimators, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b1c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(range(0,13))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f515fb2",
   "metadata": {},
   "source": [
    "\n",
    "MultinomialNB (words only, no replacement)  \n",
    "Mean: 0.9759302325581395\n",
    "Standard deviation: 0.0023139242723409837\n",
    "\n",
    "LinearSVC (pp 9, c=.1)  \n",
    "Mean: 0.9882558139534885\n",
    "Standard deviation: 0.0020604703658917765\n",
    "\n",
    "MultinomialNB (unfiltered tokens (no headers or html tags, #body_strip = re.sub(r\"[()\\\"\\'-]\", '', body_strip)))  \n",
    "Mean: 0.9853488372093022\n",
    "Standard deviation: 0.002156655464068763\n",
    "\n",
    "\n",
    "MultinomialNB (unfiltered tokens (no headers or html tags,). \n",
    "Mean: 0.9856976744186046\n",
    "Standard deviation: 0.0022845212446963464\n",
    "\n",
    "MultinomialNB (pp 0)  \n",
    "Mean: 0.9909302325581395\n",
    "Standard deviation: 0.0018964542360814004\n",
    "\n",
    "MultinomialNB (pp 1)  \n",
    "Mean: 0.9906976744186047\n",
    "Standard deviation: 0.0014708268186829627\n",
    "\n",
    "MultinomialNB (pp 2). \n",
    "Mean: 0.9894186046511628\n",
    "Standard deviation: 0.0017787277372998196\n",
    "\n",
    "MultinomialNB (3)  \n",
    "Mean: 0.9890697674418604\n",
    "Standard deviation: 0.001000270379888683\n",
    "\n",
    "MultinomialNB (4)  \n",
    "Mean: 0.9906976744186047\n",
    "Standard deviation: 0.0015160935826052818\n",
    "\n",
    "MultinomialNB (5)  \n",
    "Mean: 0.9897674418604652\n",
    "Standard deviation: 0.0016689186156287625\n",
    "\n",
    "MultinomialNB (6)  \n",
    "Mean: 0.9891860465116279\n",
    "Standard deviation: 0.001786312964620599\n",
    "\n",
    "MultinomialNB (7)  \n",
    "Mean: 0.9877906976744185\n",
    "Standard deviation: 0.0008222171874262352\n",
    "\n",
    "MultinomialNB (8)  \n",
    "Mean: 0.991046511627907\n",
    "Standard deviation: 0.002313924272340988\n",
    "\n",
    "MultinomialNB (9)  \n",
    "Mean: **0.991046511627907**\n",
    "Standard deviation: **0.0010783277320343995**\n",
    "\n",
    "MultinomialNB (10)  \n",
    "Mean: 0.9901162790697674\n",
    "Standard deviation: 0.0016850438076964278\n",
    "\n",
    "MultinomialNB (11)  \n",
    "Mean: 0.9895348837209303\n",
    "Standard deviation: 0.000636886694773442\n",
    "\n",
    "MultinomialNB (12)  \n",
    "Mean: 0.991046511627907\n",
    "Standard deviation: 0.0019317729913762727\n",
    "\n",
    "MultinomialNB (pp 13)  \n",
    "Mean: 0.9901162790697675\n",
    "Standard deviation: 0.0012195451722908676\n",
    "\n",
    "MultinomialNB (pp 14)  \n",
    "Mean: 0.9893023255813954\n",
    "Standard deviation: 0.001748057718415442\n",
    "\n",
    "MultinomialNB (preprocess 15)  \n",
    "Mean: 0.9883720930232558\n",
    "Standard deviation: 0.0011627906976744095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231fe4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_largest_user_globals():\n",
    "    ''' Returns global objects with largest memory footprint, attempting to isolate those allocated by user\n",
    "        Adapted from https://stackoverflow.com/a/40997868 by Abdou '''\n",
    "    \n",
    "    # These are the usual ipython objects, including this one you are creating\n",
    "    ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "    # Get a sorted list of the objects and their sizes\n",
    "    sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ceecb1",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c49ffc1",
   "metadata": {},
   "source": [
    "hyperparameters to your preparation pipeline to control whether or not to \n",
    "- (strip off email headers)\n",
    "- convert each email to lowercase, \n",
    "- remove punctuation, \n",
    "- replace all URLs with “URL,” \n",
    "- replace all numbers with “NUMBER,” \n",
    "- (or even perform stemming (i.e., trim off word endings; there are Python libraries available to do this).)\n",
    "\n",
    "Finally, try out several classifiers and see if you can build a great spam classifier, with both high recall and high precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87596c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading spamham_flags9.pkl\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10751 entries, 0 to 10750\n",
      "Columns: 128305 entries, is_spam to https://listman.redhat.com/\n",
      "dtypes: Sparse[int32, 0](128305)\n",
      "memory usage: 13.1 MB\n",
      "None\n",
      "0.00124088027083492\n",
      "spamham_flags9.pkl\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_train_test_data((PreprocessFlags.TO_LOWER | \n",
    "                                                        PreprocessFlags.REPLACE_NUMBERS).value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4876be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "mnb_param_grid = [\n",
    "    {'alpha': [1e-3, 1e-1,1e-2] },# 'fit_prior': [True, False] }\n",
    "  ]\n",
    "\n",
    "linsvc_param_grid = [\n",
    "    {'C' : [.19, .18, .2], 'max_iter' : [2700,2750,2650]},\n",
    "  ]\n",
    "\n",
    "linsvc_clf = LinearSVC(C=.19, max_iter=2700)\n",
    "mnb_clf = MultinomialNB(alpha=1e-2, fit_prior=False) \n",
    "\n",
    "grid_search = GridSearchCV(linsvc_clf, linsvc_param_grid, cv=5,\n",
    "                           #return_train_score=True, \n",
    "                           verbose=2)\n",
    "\n",
    "main_pipeline = Pipeline([\n",
    "    #(\"tfidf\", TfidfTransformer()),\n",
    "    #('mnb', mnb_clf),\n",
    "    #('bnb', BernoulliNB(alpha=1e-2, fit_prior=False))\n",
    "    ('cnb', ComplementNB(alpha=1e-2))#, fit_prior=False))\n",
    "#    ('linsvc', linsvc_clf),\n",
    "#    ('grid', grid_search)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c92fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_out = main_pipeline.fit(X_train, y_train)\n",
    "#print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49646249",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a691f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9921363040629095\n",
      "0.9960526315789474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9954260178049563"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "#X_test_tr = col_trans.fit_transform(X_test)\n",
    "#print(list(X_train))\n",
    "#print(list(X_test))\n",
    "\n",
    "y_test_predict = pipe_out.predict(X_test)\n",
    "print(precision_score(y_test, y_test_predict)) # first priority for spam classifier\n",
    "print(recall_score(y_test, y_test_predict))    # second priority\n",
    "score = f1_score(y_test, y_test_predict, average=\"macro\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb07d0f1",
   "metadata": {},
   "source": [
    "### Results (F1)\n",
    "\n",
    "#### MNB/CNB\n",
    "- 0.9842730411939666 url replace\n",
    "- **0.9954260178049563** (alpha=1e-2, fit_prior=False, preprocessor 9: num. replace, to lower)\n",
    "- 0.9934009451494716 (tfidf, alpha=1e-2, fit_prior=False, pp 9, )\n",
    "\n",
    "#### BNB\n",
    "- 0.9949193040934678 (alpha=1e-2, fit_prior=False, pp 9)\n",
    "\n",
    "#### LinSVC\n",
    "- 0.9913856161203258 (C=.19, max_iter=2700)\n",
    "- 0.9923721619016614 (tfidf, C=.19, max_iter=2700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffef8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
